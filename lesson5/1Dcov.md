PS C:\Users\19002\Desktop\cloud_lesson> & C:/ProgramData/anaconda3/envs/cloud_lesson/python.exe c:/Users/19002/Desktop/cloud_lesson/lesson5/1Dcov.py
[ 7.  8. 16. 14. 11.]


一维卷积（1D卷积）是信号处理和时间序列分析中的一个基础概念，它也在深度学习的上下文中被广泛使用，特别是在处理序列数据如自然语言或一维传感器数据时。

数学上，1D卷积是两个函数（通常是一个信号和一个滤波器或权重函数）之间的运算，可以被视为一个函数（信号）通过另一个函数（滤波器）的加权移动平均。这里是其数学意义：

1. **移动窗口（Moving Window）**:
   - 滤波器 \( w \) 在信号 \( x \) 上滑动，这个滤波器也称作卷积核或权重向量。
   - 卷积核的大小决定了每次运算时考虑的信号的范围。

2. **加权和（Weighted Sum）**:
   - 在每个窗口位置，信号的当前覆盖片段与卷积核进行元素乘法。
   - 这些乘积随后被加在一起，得到单一的输出值。

3. **步长（Stride）**:
   - 步长是卷积核每次滑动的元素数。步长为1意味着卷积核每次移动一个元素。
   - 步长决定了输出信号的长度，较大的步长会导致较短的输出。

4. **边界效应（Boundary Effects）**:
   - 卷积可能需要对输入信号的边界进行特殊处理，如通过填充（padding）额外的零来处理边界上的值。

5. **输出（Output）**:
   - 输出 \( y \) 是经过滤波器处理后的新信号或特征表示，它强调或弱化了原信号的某些方面。

在深度学习中，1D卷积的数学意义得到了扩展，用于自动学习从数据中提取特征的最佳滤波器。在这个上下文中，卷积核的权重是通过学习算法（如反向传播和梯度下降）自动调整的，以最小化某种损失函数。这允许模型在训练过程中学习如何最有效地表示输入数据，以进行分类、预测或其他任务。

在您提供的例子中，1D卷积被用来计算一个简单的时间序列信号 \( x \) 通过一个离散滤波器 \( w \) 的输出 \( y \)。这个过程可以用来检测信号中的模式、突变或其他关键特征，这些特征可能会在原始信号中不那么明显。

--------------------------------------------------------------------------------

这张图片展示了卷积神经网络（CNN）中卷积层和多层感知机（MLP，也称为全连接层）之间的主要区别。

左侧的“卷积”部分表示了卷积层如何工作。在这个例子中，一个卷积核（或滤波器）在输入序列上滑动。这个卷积核包含一组权重（在这个例子中为三个权重，分别用灰色表示）。当卷积核滑过输入数据时（由1、0和2组成的序列），它每次只覆盖三个数字，并对其应用相同的权重。这意味着网络可以识别局部模式，并且同一组权重在整个数据序列上重复使用。因此，卷积层的参数数量远少于全连接层，并且它们能够捕捉到输入数据的空间层次结构。

右侧的“MLP (fully connected)”部分表示了一个典型的多层感知机或全连接层，其中每个输入单元都与下一层的每个单元连接。这意味着输入数据的每个部分都与下一层的每个神经元有独立的权重连接。全连接层不考虑输入数据的空间结构，参数数量也多得多。在这个例子中，输出层的每个节点收到了来自所有输入节点的不同加权信号，从而可以组合各种属性来形成更复杂的表示。

从图中的颜色编码可以看出，卷积层的输出（左图的蓝色数字5）是通过应用相同的权重（表示局部连接）到输入数据的不同部分而生成的，反映了局部模式。而全连接层的输出（右图的数字5、7和1）是输入的全局加权和，每个输出节点都基于所有输入节点的不同权重计算得出。

简而言之，卷积操作保留了输入数据的空间关系并且参数共享，而全连接层则没有空间关系保留，并且每个连接都有独立的参数。这使得卷积神经网络在处理图像等具有空间相关性的数据时特别有效，而多层感知机则适合处理不需要考虑输入特征间空间关系的问题。

stride，是卷积每次移动的步长